{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在实际工作中，FM和MF哪个应用的更多?\n",
    "FM:因子分解机，是一种基于矩阵分解思想的机器学习算法，是为了结局大规模稀疏矩阵中特征组合的问题。\n",
    "MF：矩阵分解，将用户与物品嵌入到一个共同的低维空间内。\n",
    "MF是FM的一个特例。\n",
    "FM降低时间复杂度为k*n。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FFM与FM有哪些区别？\n",
    "FFM在FM的基础上引入了field的概念，每个特征的隐向量不在只有一个，而是针对每个field学习一个独立的隐向量，防止互相影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepFM相比于FM解决了哪些问题，原理是怎样的？\n",
    "DeepFM = FM+DNN ,可以考虑低阶，又能考虑到高阶的特征工程。因子分解机FM提取低阶的特征，神经网络DNN提取高阶特征。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprise工具中的baseline算法原理是怎样的？BaselineOnly和KNNBaseline有什么区别？\n",
    "baseline算法：基于统计的基准预测线打分，bui = μ+bu+bi\n",
    "使用ALS进行优化，step1：固定bu，优化bi， step2：固定bi，优化bu。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#action使用libfm工具对movielens进行评分预测，采用SGD优化算法\n",
    "libFM -task r -train ratings.dat.libfm -test ratings.dat.libfm -dim '1,1,8' -method sgd -learn_rate 0.01 -regular ’0,0,0.01’ -out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#action2使用DeepFM对movielens进行评分预测\n",
    "import pandas as pd\n",
    "from deepctr.models import DeepFM\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepctr.1 import SparseFeat,get_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\zhanghangbo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "[SparseFeat(name='movie_id', vocabulary_size=187, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x000001B4E763F278>, embedding_name='movie_id', group_name='default_group', trainable=True), SparseFeat(name='user_id', vocabulary_size=193, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x000001B4E7661EF0>, embedding_name='user_id', group_name='default_group', trainable=True), SparseFeat(name='gender', vocabulary_size=2, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x000001B4E7661F28>, embedding_name='gender', group_name='default_group', trainable=True), SparseFeat(name='age', vocabulary_size=7, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x000001B4E7687080>, embedding_name='age', group_name='default_group', trainable=True), SparseFeat(name='occupation', vocabulary_size=20, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x000001B4E76870F0>, embedding_name='occupation', group_name='default_group', trainable=True), SparseFeat(name='zip', vocabulary_size=188, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x000001B4E7687160>, embedding_name='zip', group_name='default_group', trainable=True)]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\zhanghangbo\\Desktop\\数据挖掘算法\\第五周\\L5\\deepfm\\movielens_sample.txt\")\n",
    "data.shape\n",
    "sparse_features = [\"movie_id\",\"user_id\",\"gender\",\"age\",\"occupation\",\"zip\"]\n",
    "target = [\"rating\"]\n",
    "#对特征标签进行编码\n",
    "for feature in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feature]= lbe.fit_transform(data[feature])\n",
    "# 计算每个特征中的 不同特征值的个数\n",
    "fixlen_feature_columns = [SparseFeat(feature, data[feature].nunique()) for feature in sparse_features]\n",
    "print(fixlen_feature_columns)\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\zhanghangbo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From c:\\users\\zhanghangbo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\deepctr\\layers\\utils.py:167: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 128 samples, validate on 32 samples\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 14.3671 - mean_squared_error: 14.3671 - val_loss: 13.7776 - val_mean_squared_error: 13.7776\n",
      "test RMSE 3.678314831549904\n"
     ]
    }
   ],
   "source": [
    "# 将数据集切分成训练集和测试集\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train_model_input = {name:train[name].values for name in feature_names}\n",
    "test_model_input = {name:test[name].values for name in feature_names}\n",
    "\n",
    "# 使用DeepFM进行训练\n",
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression')\n",
    "model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = model.fit(train_model_input, train[target].values, batch_size=256, epochs=1, verbose=True, validation_split=0.2, )\n",
    "# 使用DeepFM进行预测\n",
    "pred_ans = model.predict(test_model_input, batch_size=256)\n",
    "# 输出RMSE或MSE\n",
    "mse = round(mean_squared_error(test[target].values, pred_ans), 4)\n",
    "rmse = mse ** 0.5\n",
    "print(\"test RMSE\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparseFeat(name='userId', vocabulary_size=7120, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x000001B4E7661AC8>, embedding_name='userId', group_name='default_group', trainable=True), SparseFeat(name='movieId', vocabulary_size=14026, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x000001B4E7661A90>, embedding_name='movieId', group_name='default_group', trainable=True)]\n"
     ]
    }
   ],
   "source": [
    "#movielens数据集\n",
    "data = pd.read_csv(r\"C:\\Users\\zhanghangbo\\Desktop\\数据挖掘算法\\第五周\\L5\\libfm\\ratings.csv\")\n",
    "data.head(5)\n",
    "sparse_features = [\"userId\",\"movieId\"]\n",
    "target = [\"rating\"]\n",
    "#对特征标签进行编码\n",
    "for feature in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feature]= lbe.fit_transform(data[feature])\n",
    "# 计算每个特征中的 不同特征值的个数\n",
    "fixlen_feature_columns = [SparseFeat(feature, data[feature].nunique()) for feature in sparse_features]\n",
    "print(fixlen_feature_columns)\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 671088 samples, validate on 167772 samples\n",
      "671088/671088 [==============================] - 4s 6us/sample - loss: 0.9522 - mean_squared_error: 0.9514 - val_loss: 0.7436 - val_mean_squared_error: 0.7420\n",
      "test RMSE 0.8616843969807043\n"
     ]
    }
   ],
   "source": [
    "# 将数据集切分成训练集和测试集\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train_model_input = {name:train[name].values for name in feature_names}\n",
    "test_model_input = {name:test[name].values for name in feature_names}\n",
    "\n",
    "# 使用DeepFM进行训练\n",
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression')\n",
    "model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = model.fit(train_model_input, train[target].values, batch_size=256, epochs=1, verbose=True, validation_split=0.2, )\n",
    "# 使用DeepFM进行预测\n",
    "pred_ans = model.predict(test_model_input, batch_size=256)\n",
    "# 输出RMSE或MSE\n",
    "mse = round(mean_squared_error(test[target].values, pred_ans), 4)\n",
    "rmse = mse ** 0.5\n",
    "print(\"test RMSE\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#action使用基于邻域的协同过滤（KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline中的任意一种）\n",
    "#对MovieLens数据集进行协同过滤，采用k折交叉验证(k=3)，输出每次计算的RMSE, MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBasic\n",
    "from surprise import Dataset,Reader\n",
    "from surprise.accuracy  import rmse\n",
    "from surprise.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9023\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9025\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9053\n"
     ]
    }
   ],
   "source": [
    "#数据读取\n",
    "reader = Reader(line_format=\"user item rating timestamp\",sep=\",\",skip_lines=1)\n",
    "data = Dataset.load_from_file(r\"C:\\Users\\zhanghangbo\\Desktop\\数据挖掘算法\\第五周\\L5\\libfm\\ratings.csv\",reader=reader)\n",
    "train_set =data.build_full_trainset()\n",
    "#itemcf计算得分\n",
    "algo = KNNBasic(k=50,sim_options={\"user_based\":True})\n",
    "kf = KFold(n_splits=3)\n",
    "for trainset,testet in kf.split(data):\n",
    "    algo.fit(trainset)\n",
    "    pred = algo.test(testet)\n",
    "    rmse(pred,verbose=True)\n",
    "uid = str(196)\n",
    "lid = str(302)\n",
    "predction = algo.predict(uid,lid) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
